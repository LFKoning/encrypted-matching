{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy names.\n",
    "n = 50_000\n",
    "faker = Faker(locale=\"nl-NL\")\n",
    "faker.seed_instance(42)\n",
    "names = pd.Series([faker.name() for _ in range(n)])\n",
    "names.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cryptography.fernet import Fernet\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "class EncryptedMatcher:\n",
    "    \"\"\"Fuzzy matching for large sets of encrypted names.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        encryption_key,\n",
    "        storage_path: str,\n",
    "        topn: int = 10,\n",
    "        encoding: str = \"utf8\",\n",
    "        n_features: int = 2**20,\n",
    "    ):\n",
    "        self._encryptor = Fernet(encryption_key)\n",
    "        self._topn = -topn\n",
    "        self._encoding = encoding\n",
    "\n",
    "        self._storage_path = Path(storage_path)\n",
    "        self._storage_path.mkdir(exist_ok=True)\n",
    "        self._database = self._setup_database()        \n",
    "        self._vectors = self._load_vectors()\n",
    "\n",
    "        self._vectorizer = HashingVectorizer(\n",
    "            encoding=encoding,\n",
    "            n_features=n_features,\n",
    "            ngram_range=(3, 3),\n",
    "            analyzer=\"char_wb\",\n",
    "            lowercase=True,\n",
    "            strip_accents=\"ascii\",\n",
    "        )\n",
    "\n",
    "    def _setup_database(self):\n",
    "        \"\"\"Sets up the SQLite database.\"\"\"\n",
    "        database = sqlite3.connect(self._storage_path / \"encrypted.db\")\n",
    "        database.execute(\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS MatchData (\n",
    "                MatchIndex INTEGER PRIMARY KEY,\n",
    "                MatchData BLOB\n",
    "            );\n",
    "            \"\"\"\n",
    "        )\n",
    "        database.commit()\n",
    "        return database\n",
    "\n",
    "    def _load_vectors(self):\n",
    "        \"\"\"Load stored vectors.\"\"\"\n",
    "        try:\n",
    "            return sparse.load_npz(self._storage_path / \"vectors.npz\")\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "\n",
    "    def _store_vectors(self, vectors):\n",
    "        \"\"\"Store vectors to disk.\"\"\"\n",
    "        if self._vectors:\n",
    "            self._vectors = sparse.vstack([self._vectors, vectors])\n",
    "        else:\n",
    "            self._vectors = vectors\n",
    "        sparse.save_npz(self._storage_path / \"vectors.npz\", vectors)        \n",
    "\n",
    "    def _load_data(self, indices):\n",
    "        \"\"\"Retrieve encrypted data from SQLite.\"\"\"\n",
    "        query = \"SELECT * FROM MatchData WHERE MatchIndex IN (%s)\"\n",
    "        query = query % \", \".join(\"?\" * len(indices))\n",
    "        result = self._database.execute(query, indices.tolist())\n",
    "        return result.fetchall()\n",
    "        \n",
    "    def _store_data(self, names):\n",
    "        \"\"\"Store encrypted data to SQLite.\"\"\"\n",
    "        data = pd.DataFrame({\n",
    "            \"MatchedIndex\": names.index,\n",
    "            \"MatchedData\": names.map(self._encrypt_data)\n",
    "        })\n",
    "        self._database.executemany(\n",
    "            \"INSERT INTO MatchData (MatchIndex, MatchData) VALUES (?, ?);\",\n",
    "            data.values\n",
    "        )\n",
    "        self._database.commit()\n",
    "\n",
    "    def _encrypt_data(self, data):\n",
    "        \"\"\"Encrypts data using Fernet encryption.\"\"\"\n",
    "        return self._encryptor.encrypt(data.encode(self._encoding))\n",
    "\n",
    "    def _decrypt_data(self, data):\n",
    "        \"\"\"Decrypts data using Fernet encryption.\"\"\"\n",
    "        # Decode to string or leave as bytes?\n",
    "        return self._encryptor.decrypt(data).decode(self._encoding)\n",
    "\n",
    "    def add_names(self, names: pd.Series):\n",
    "        \"\"\"Store encrypted and vectorized names.\"\"\"\n",
    "        self._store_data(names)\n",
    "        vectors = self._vectorizer.fit_transform(names)\n",
    "        self._store_vectors(vectors)\n",
    "        \n",
    "    def search(self, targets: str):\n",
    "        \"\"\"Search names in the vector space.\"\"\"\n",
    "        target_vectors = self._vectorizer.fit_transform(targets)\n",
    "\n",
    "        similarities = cosine_similarity(target_vectors, self._vectors)\n",
    "        top_matches = np.argpartition(similarities, self._topn)[:, self._topn:]\n",
    "        print(top_matches)\n",
    "\n",
    "        results = []\n",
    "        for target_index, matched_indices in enumerate(top_matches):\n",
    "            matched_rows = self._load_data(matched_indices)\n",
    "            for match_index, match_data in matched_rows:\n",
    "                results.append({\n",
    "                    \"name\": targets[target_index],\n",
    "                    \"target\": self._decrypt_data(match_data),\n",
    "                    \"encrypted\": match_data,\n",
    "                    \"similarity\": float(similarities[target_index, match_index]),\n",
    "                })\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encryption_key = Fernet.generate_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = EncryptedMatcher(\n",
    "    encryption_key=encryption_key,\n",
    "    storage_path=\"vector_store\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add_names(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.search([\"Ali Schellekens\", \"Alicia Schellekens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encrypted-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
