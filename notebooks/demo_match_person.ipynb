{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO: Match Natural Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "from fuzzy_matching.match_multi import MultiMatcher\n",
    "from fuzzy_matching.encryption import AESGCM4Encryptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Faker\n",
    "faker = Faker(locale=\"nl-NL\")\n",
    "faker.seed_instance(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ids(n):\n",
    "    \"\"\"Generate ID-like strings.\"\"\"\n",
    "    country_code = \"NLD\"\n",
    "\n",
    "    ids = []\n",
    "    for _ in range(n):\n",
    "        gender = random.choice([\"M\", \"F\"])\n",
    "        first = f\"{random.randint(0, 9999999):07d}\"\n",
    "        second = f\"{random.randint(0, 9999999999999999):016d}\"\n",
    "        ids.append(f\"{country_code}{first}{gender}{second}\")\n",
    "    return ids\n",
    "\n",
    "\n",
    "def generate_names(n):\n",
    "    \"\"\"Generate dummy names.\"\"\"\n",
    "    return pd.Series([faker.name() for _ in range(n)])\n",
    "\n",
    "\n",
    "def generate_birthdates(n):\n",
    "    \"\"\"Generate dummy birthdates.\"\"\"\n",
    "    return pd.Series(\n",
    "        [\n",
    "            faker.date_of_birth(minimum_age=18, maximum_age=100).strftime(\"%d-%m-%Y\")\n",
    "            for _ in range(n)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def make_ids(n) -> str:\n",
    "    \"\"\"Generate a UUID4 identifier.\"\"\"\n",
    "    return [uuid.uuid4().hex for _ in range(n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50_000\n",
    "data = pd.DataFrame({\n",
    "    \"uuid\": make_ids(n),\n",
    "    \"name\": generate_names(n),\n",
    "    \"birthdate\": generate_birthdates(n),\n",
    "    \"national_id\": generate_ids(n),\n",
    "})\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encryption_key = AESGCM4Encryptor.generate_key()\n",
    "encryption_key = b\"\\x0e\\x84\\xa1\\x01\\xd0\\xed\\x932\\xb5\\x1dt\\x11\\x05\\xe5j\\xf8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"name\": {\n",
    "        \"algoritm\": \"vector\",\n",
    "        \"weight\": 0.2,\n",
    "    },\n",
    "    \"birthdate\": {\n",
    "        \"algoritm\": \"timedelta\",\n",
    "        \"format\": \"%d-%m-%Y\",\n",
    "        \"weight\": 0.2,\n",
    "    },\n",
    "    \"national_id\": {\n",
    "        \"algoritm\": \"alignment\",\n",
    "        \"weight\": 0.6\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = MultiMatcher(10, config, encryption_key, \"storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.create(data, id_column=\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = matcher.get({\n",
    "    \"name\": \"Sepp Ketting\",\n",
    "    \"birthdate\": \"6-5-1924\",\n",
    "    \"national_id\": \"nld4011381f3815034902574046\"\n",
    "})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dedupe testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import random\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ids(n):\n",
    "    \"\"\"Generate ID-like strings.\"\"\"\n",
    "    country_code = \"NLD\"\n",
    "\n",
    "    ids = []\n",
    "    for _ in range(n):\n",
    "        gender = random.choice([\"M\", \"F\"])\n",
    "        first = f\"{random.randint(0, 9999999):07d}\"\n",
    "        second = f\"{random.randint(0, 9999999999999999):016d}\"\n",
    "        ids.append(f\"{country_code}{first}{gender}{second}\")\n",
    "    return ids\n",
    "\n",
    "def make_id() -> str:\n",
    "    \"\"\"Generate a UUID4 identifier.\"\"\"\n",
    "    return uuid.uuid4().hex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3_000\n",
    "values = pd.DataFrame({\n",
    "    \"value\": generate_ids(n),\n",
    "    \"uuid\": [make_id() for _ in range(n)]\n",
    "})\n",
    "\n",
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add duplicates\n",
    "previous = values\n",
    "for ndupes in 800, 300, 100:\n",
    "    dupes = pd.DataFrame({\n",
    "        \"value\": previous[\"value\"].sample(ndupes).values,\n",
    "        \"uuid\": [make_id() for _ in range(ndupes)]\n",
    "    })\n",
    "\n",
    "    previous = dupes\n",
    "    values = pd.concat([values, dupes])\n",
    "\n",
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values[\"duplicate_uuid\"] = values.groupby(by=\"value\", as_index=False)[\"uuid\"].transform(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped = values.groupby(by=\"value\", as_index=False).agg(uuid=(\"uuid\", list))\n",
    "mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance.OSA import normalized_similarity\n",
    "from rapidfuzz.process import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    mapped.assign(\n",
    "        score=cdist(\n",
    "            [\"NLD0007781F8760032249488398\"],\n",
    "            mapped[\"value\"],\n",
    "            scorer=normalized_similarity,\n",
    "            workers=-1,\n",
    "        )[0]\n",
    "    )\n",
    "    .explode(\"uuid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(items):\n",
    "    for item in items:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            yield from flatten(item)\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(flatten([\"111\", [\"222\", \"333\"], \"444\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"id\": [\"a\", \"b\", \"c\", \"d\"],\n",
    "    \"value\": [\"a\", \"a\", \"b\", \"c\"],\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"id\": [\"e\", \"f\", \"g\", \"h\"],\n",
    "    \"value\": [\"a\", \"c\", \"d\", \"e\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df1.groupby(\"value\", as_index=False).agg(lambda ids: list(flatten(ids)))\n",
    "grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([grp, df2]).groupby(\"value\", as_index=False).agg(lambda ids: list(flatten(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
